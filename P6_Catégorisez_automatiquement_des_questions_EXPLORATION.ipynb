{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "P6_Catégorisez_automatiquement_des_questions_EXPLORATION.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_58u4WCCoZ7"
      },
      "source": [
        "# Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kd-TASrZfORb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebbbd760-3da2-4e18-f071-abcdd7423636"
      },
      "source": [
        "#pip install num2words\r\n",
        "!pip install unidecode"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/25/723487ca2a52ebcee88a34d7d1f5a4b80b793f179ee0f62d5371938dfa01/Unidecode-1.2.0-py2.py3-none-any.whl (241kB)\n",
            "\r\u001b[K     |█▍                              | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20kB 22.8MB/s eta 0:00:01\r\u001b[K     |████                            | 30kB 12.1MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 40kB 9.5MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 81kB 8.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 122kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 133kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 153kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 163kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 174kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 184kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 194kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 204kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 215kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 225kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 235kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 245kB 6.1MB/s \n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYdDOT47fLO7",
        "outputId": "c685600e-3910-4b34-ab55-c7c7bdcd6224"
      },
      "source": [
        "import os\r\n",
        "import pandas as pd\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')\r\n",
        "from nltk.corpus import stopwords, wordnet\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "#from lxml import etree\r\n",
        "from collections import defaultdict, Counter\r\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from sklearn import metrics, cluster, preprocessing\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import csv\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "import seaborn as sns\r\n",
        "%matplotlib inline\r\n",
        "from sklearn import manifold, decomposition\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\r\n",
        "from sklearn.neighbors import KNeighborsClassifier\r\n",
        "from sklearn.ensemble \\\r\n",
        "import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\r\n",
        "from sklearn.svm import LinearSVC, SVC\r\n",
        "import timeit\r\n",
        "import itertools\r\n",
        "import unidecode\r\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xXFBWEHdpdL",
        "outputId": "a4ea9d95-3637-4d67-cecb-44ade87427ef"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive') \r\n",
        "import sys\r\n",
        "sys.path.append(\"/content/drive/My Drive/Colab Notebooks\")\r\n",
        "import os \r\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/P6_Catégorisez automatiquement des questions')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtPqqEICJmfA"
      },
      "source": [
        "# Constantes et fonctions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE_5rYy1sLFF"
      },
      "source": [
        "TOP = 50\r\n",
        "REGEX = '[a-z0-9]+[#-]?\\+{0,2}[a-z0-9]*'\r\n",
        "\r\n",
        "# Extra stopwords = radicaux qui ne me semblent pas discriminants \r\n",
        "EXTRA_SW = ('use', 'get', 'like', 'way', 'creat', 'would', 'want', 'need',\\\r\n",
        "            'know', 'could', 'x', 'xx', 'xyz', 'aa', 'xxx', 'z', 'yyyi', 'wont',\\\r\n",
        "            'aaa', 'aaaaaa', 'aabbc', 'aandb', 'aarrggbb', 'without', 'behind', \\\r\n",
        "            'within')\r\n",
        "\r\n",
        "def conv_html(col):\r\n",
        "    \"\"\"\r\n",
        "    Fonction de convertion de html en chaine standard\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    html = BeautifulSoup(col, 'html.parser')\r\n",
        "    # Delete url strings\r\n",
        "    for t in html.find_all('a'):\r\n",
        "        t.replace_with('')\r\n",
        "    # Delete code blocks\r\n",
        "    for t in html.find_all('pre'):\r\n",
        "        t.replace_with('')\r\n",
        "    \r\n",
        "    return html.get_text(' ', strip=True)\r\n",
        "\r\n",
        "def clean_field(col, tknzr, sw, lmtzr, stmr):\r\n",
        "    \"\"\"\r\n",
        "    Fonction de tokenisation du contenu dont regex \\w+, \r\n",
        "    suppression des stopwords, lemmatisation et racinisation\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    temp = []\r\n",
        "    \r\n",
        "    for w in tknzr.tokenize(unidecode.unidecode(col).lower()):\r\n",
        "        if w not in sw and not w.isdigit():\r\n",
        "            pos = get_wordnet_pos(w)\r\n",
        "            if pos != 'n':\r\n",
        "                continue\r\n",
        "            else:\r\n",
        "                temp.append(stmr.stem(lmtzr.lemmatize(w, pos)))\r\n",
        "            \r\n",
        "    return ' '.join(temp)\r\n",
        "\r\n",
        "def get_wordnet_pos(word):\r\n",
        "    \"\"\"\r\n",
        "    Map POS tag to first character lemmatize() accepts\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    tag = nltk.pos_tag([word])[0][1][0].upper()\r\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\r\n",
        "                \"N\": wordnet.NOUN,\r\n",
        "                \"V\": wordnet.VERB,\r\n",
        "                \"R\": wordnet.ADV}\r\n",
        "\r\n",
        "    return tag_dict.get(tag, wordnet.NOUN)\r\n",
        "\r\n",
        "def recap_cols(df, cols):\r\n",
        "    \"\"\"\r\n",
        "    Fonction de dénombrement du contenu des listes des colonnes (cols) de df\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    print('='*50, '\\nDénombrenent des mots')\r\n",
        "    \r\n",
        "    for col in cols:\r\n",
        "        freq[col] = Counter(' '.join(df[col].values).split()).most_common()\r\n",
        "        print('\\t{:6s} : {:>7d} dont {:>6d} distincts'.\\\r\n",
        "                format(col, sum(dict(freq[col]).values()), len(freq[col])))\r\n",
        "    print('='*50)\r\n",
        "        \r\n",
        "    return freq"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bt_3CT4ZW8O"
      },
      "source": [
        "# Chargement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "PsNdhme0fm5V",
        "outputId": "484f37c3-337e-45f9-c560-19a996ac43e1"
      },
      "source": [
        "freq = defaultdict()\r\n",
        "\r\n",
        "train = pd.read_csv(\"db_StackOverflow.csv\", header=0, encoding='utf-8', \\\r\n",
        "                    delimiter=',', quotechar='\"', index_col=0, )\r\n",
        "train.rename_axis(None, inplace=True)\r\n",
        "train = train.apply(lambda x: x.astype(str).str.lower())\r\n",
        "cols = train.columns\r\n",
        "\r\n",
        "print(train.info())\r\n",
        "\r\n",
        "freq = recap_cols(train, cols) \r\n",
        "\r\n",
        "train.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 50000 entries, 169828 to 1669645\n",
            "Data columns (total 3 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Title   50000 non-null  object\n",
            " 1   Body    50000 non-null  object\n",
            " 2   Tags    50000 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 1.5+ MB\n",
            "None\n",
            "================================================== \n",
            "Dénombrenent des mots\n",
            "\tTitle  :  428719 dont  37241 distincts\n",
            "\tBody   : 6055132 dont 561841 distincts\n",
            "\tTags   :   50000 dont  37101 distincts\n",
            "==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169828</th>\n",
              "      <td>what are the real benefits of visual studio te...</td>\n",
              "      <td>&lt;p&gt;interested if anyone has used vsts database...</td>\n",
              "      <td>&lt;sql-server&gt;&lt;database-tools&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431644</th>\n",
              "      <td>how can i hook into the current formsauthentic...</td>\n",
              "      <td>&lt;p&gt;i've got an httpmodule in my application th...</td>\n",
              "      <td>&lt;asp.net&gt;&lt;events&gt;&lt;forms-authentication&gt;&lt;httpmo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1450121</th>\n",
              "      <td>is there any sync algorithm/reference availabl...</td>\n",
              "      <td>&lt;p&gt;i'm planning to write a program to sync a f...</td>\n",
              "      <td>&lt;algorithm&gt;&lt;synchronization&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426609</th>\n",
              "      <td>how to assign profile values?</td>\n",
              "      <td>&lt;p&gt;i don't know what i am missing, but i added...</td>\n",
              "      <td>&lt;asp.net&gt;&lt;asp.net-mvc&gt;&lt;asp.net-membership&gt;&lt;pro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14646</th>\n",
              "      <td>how to add \"project description\" in fogbugz?</td>\n",
              "      <td>&lt;p&gt;when i create a new project (or even when i...</td>\n",
              "      <td>&lt;fogbugz&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Title  ...                                               Tags\n",
              "169828   what are the real benefits of visual studio te...  ...                       <sql-server><database-tools>\n",
              "431644   how can i hook into the current formsauthentic...  ...  <asp.net><events><forms-authentication><httpmo...\n",
              "1450121  is there any sync algorithm/reference availabl...  ...                       <algorithm><synchronization>\n",
              "426609                       how to assign profile values?  ...  <asp.net><asp.net-mvc><asp.net-membership><pro...\n",
              "14646         how to add \"project description\" in fogbugz?  ...                                          <fogbugz>\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yE51lHCta7p"
      },
      "source": [
        "# Nettoyage du dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "id": "X7jblBHhtNqE",
        "outputId": "179deada-5753-4438-bfb7-d824e143946d"
      },
      "source": [
        "# Stopwords nltk \r\n",
        "std_sw = set(nltk.corpus.stopwords.words('english')) \r\n",
        "\r\n",
        "tokenizer = nltk.RegexpTokenizer(REGEX)\r\n",
        "lemmatizer = WordNetLemmatizer() \r\n",
        "stemmer = PorterStemmer()\r\n",
        "\r\n",
        "print('='*50)\r\n",
        "\r\n",
        "for col in ['Title', 'Body']:\r\n",
        "    if col == 'Body':\r\n",
        "        print('Conversion html de \"{}\" '.format(col), end='')\r\n",
        "        start_time = timeit.default_timer()\r\n",
        "\r\n",
        "        # Convertion du html en chaine standard \r\n",
        "        train[col] = train[col].apply(conv_html)\r\n",
        "\r\n",
        "        elapsed = timeit.default_timer() - start_time\r\n",
        "        print('-> OK en {:.3} sec'.format(elapsed))\r\n",
        "\r\n",
        "    print('Nettoyage/lemmatisation de \"{}\" '.format(col), end='')\r\n",
        "    start_time = timeit.default_timer()\r\n",
        "\r\n",
        "    # Tokenisation et suppression des stopwords\r\n",
        "    train[col] = train[col].apply(clean_field, tknzr=tokenizer, \\\r\n",
        "                                  sw=std_sw, lmtzr=lemmatizer, stmr=stemmer)\r\n",
        "\r\n",
        "    # Suppression des radicaux qui ne me semblent pas discriminants (ex. use, ...)\r\n",
        "    # et des chiffres (1, 0, 2003, ...)\r\n",
        "    train[col] = train[col].apply(lambda x: ' '.join([w for w in x.split() \\\r\n",
        "                                                      if w not in EXTRA_SW]))\r\n",
        "\r\n",
        "    elapsed = timeit.default_timer() - start_time\r\n",
        "    print('-> OK en {:.3} sec'.format(elapsed))\r\n",
        "\r\n",
        "print('Traitement des tags ', end='')\r\n",
        "start_time = timeit.default_timer()\r\n",
        "\r\n",
        "# Epurage et tri des tags\r\n",
        "train['Tags'] = train['Tags'].apply(lambda x: ' '.join(sorted(x[1:-1].split('><'))))\r\n",
        "\r\n",
        "# Ajout du nombre de Tags \r\n",
        "train['nTags'] = train['Tags'].apply(lambda x: len(x.split()))\r\n",
        "\r\n",
        "# Etiquetage des tags\r\n",
        "#train['Tags_lbl'] = lbl.fit_transform(train.Tags)\r\n",
        "\r\n",
        "elapsed = timeit.default_timer() - start_time\r\n",
        "print('-> OK en {:.3} sec'.format(elapsed))\r\n",
        "\r\n",
        "freq = recap_cols(train, cols)\r\n",
        "\r\n",
        "print('{} groupes de tags distincts'.format(len(train.Tags.value_counts())))\r\n",
        "print('='*50)\r\n",
        "\r\n",
        "train.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==================================================\n",
            "Nettoyage/lemmatisation de \"Title\" -> OK en 47.6 sec\n",
            "Conversion html de \"Body\" -> OK en 19.2 sec\n",
            "Nettoyage/lemmatisation de \"Body\" "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/unidecode/__init__.py:131: RuntimeWarning: Surrogate character '\\ud800' will be ignored. You might be using a narrow Python build.\n",
            "  repl = _get_repl_str(char)\n",
            "/usr/local/lib/python3.7/dist-packages/unidecode/__init__.py:131: RuntimeWarning: Surrogate character '\\udf30' will be ignored. You might be using a narrow Python build.\n",
            "  repl = _get_repl_str(char)\n",
            "/usr/local/lib/python3.7/dist-packages/unidecode/__init__.py:131: RuntimeWarning: Surrogate character '\\udf3d' will be ignored. You might be using a narrow Python build.\n",
            "  repl = _get_repl_str(char)\n",
            "/usr/local/lib/python3.7/dist-packages/unidecode/__init__.py:131: RuntimeWarning: Surrogate character '\\udf33' will be ignored. You might be using a narrow Python build.\n",
            "  repl = _get_repl_str(char)\n",
            "/usr/local/lib/python3.7/dist-packages/unidecode/__init__.py:131: RuntimeWarning: Surrogate character '\\udf3f' will be ignored. You might be using a narrow Python build.\n",
            "  repl = _get_repl_str(char)\n",
            "/usr/local/lib/python3.7/dist-packages/unidecode/__init__.py:131: RuntimeWarning: Surrogate character '\\udf42' will be ignored. You might be using a narrow Python build.\n",
            "  repl = _get_repl_str(char)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-> OK en 3.62e+02 sec\n",
            "Traitement des tags -> OK en 0.0938 sec\n",
            "================================================== \n",
            "Dénombrenent des mots\n",
            "\tTitle  :  215353 dont  13682 distincts\n",
            "\tBody   : 1584030 dont  51707 distincts\n",
            "\tTags   :  145824 dont  10494 distincts\n",
            "==================================================\n",
            "36891 groupes de tags distincts\n",
            "==================================================\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Body</th>\n",
              "      <th>Tags</th>\n",
              "      <th>nTags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>169828</th>\n",
              "      <td>benefit studio team system databas edit gdr</td>\n",
              "      <td>anyon vst databas edit featur standard studio ...</td>\n",
              "      <td>database-tools sql-server</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431644</th>\n",
              "      <td>hook formsauthenticationmodul medium trust env...</td>\n",
              "      <td>httpmodul applic hook formsauthenticationmodul...</td>\n",
              "      <td>asp.net events forms-authentication httpmodule...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1450121</th>\n",
              "      <td>sync algorithm refer directori</td>\n",
              "      <td>plan write program sync folder time across mul...</td>\n",
              "      <td>algorithm synchronization</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426609</th>\n",
              "      <td>assign profil valu</td>\n",
              "      <td>profil properti web config file cannot access ...</td>\n",
              "      <td>asp.net asp.net-membership asp.net-mvc profile</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14646</th>\n",
              "      <td>project descript fogbugz</td>\n",
              "      <td>project edit sampl project descript project blind</td>\n",
              "      <td>fogbugz</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     Title  ... nTags\n",
              "169828         benefit studio team system databas edit gdr  ...     2\n",
              "431644   hook formsauthenticationmodul medium trust env...  ...     5\n",
              "1450121                     sync algorithm refer directori  ...     2\n",
              "426609                                  assign profil valu  ...     4\n",
              "14646                             project descript fogbugz  ...     1\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5o1I1o0mFlm5"
      },
      "source": [
        "train['full']  = train.Title + ' ' + train.Body"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8l_Oi6Mgs-_"
      },
      "source": [
        "## Nombre de mots dans les Title"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVBa7cYSfTse"
      },
      "source": [
        "temp = pd.DataFrame()\r\n",
        "temp['len'] = train.Title.apply(lambda x: len(x.split()))\r\n",
        "temp.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INdXnqRThKz8"
      },
      "source": [
        "## Nombre de mots dans les Body"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NolQXM5fhRO0"
      },
      "source": [
        "temp = pd.DataFrame()\r\n",
        "temp['len'] = train.Body.apply(lambda x: len(x.split()))\r\n",
        "temp.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2E0t1JahEAA8"
      },
      "source": [
        "backup = train.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3mOSHtfW9Dc"
      },
      "source": [
        "# Explorations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSDaqNRrYJl_"
      },
      "source": [
        "## Jeu de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHm5r6f-a8iw"
      },
      "source": [
        "cpt = 0 \r\n",
        "fig = plt.figure(figsize=(25, 10))\r\n",
        "\r\n",
        "for col in cols[:-1]:\r\n",
        "    cpt += 1\r\n",
        "    plt.subplot(1, 3, cpt)\r\n",
        "    plt.barh([k for k, v in sorted(freq[col][:TOP], key=lambda x: x[1])], \r\n",
        "             [v for k, v in sorted(freq[col][:TOP], key=lambda x: x[1])])\r\n",
        "    plt.title('Top {} des radicaux dans {}'.format(TOP, col))\r\n",
        "\r\n",
        "temp = train.Tags.value_counts().to_frame('counts')\r\n",
        "plt.subplot(133)\r\n",
        "plt.barh(temp.sort_values(by='counts', ascending=True)[-TOP:].index, \r\n",
        "         temp.sort_values(by='counts', ascending=True)[-TOP:].counts)\r\n",
        "plt.title('Top {} dans Tags'.format(TOP))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9dntiR-YT40"
      },
      "source": [
        "## Top Tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwChE7cq0Q52"
      },
      "source": [
        "fig = plt.figure(figsize=(25, 10))\r\n",
        "plt.subplot(131)\r\n",
        "plt.barh([k for k, v in sorted(freq['Tags'][:TOP], key=lambda x: x[1])], \r\n",
        "         [v for k, v in sorted(freq['Tags'][:TOP], key=lambda x: x[1])])\r\n",
        "plt.title('Top {} des tags unitaires'.format(TOP))\r\n",
        "\r\n",
        "temp = pd.DataFrame.from_dict(dict(freq['Tags'][:TOP]), orient='index')\\\r\n",
        "                              .rename(columns={0:'counts'})\r\n",
        "plt.subplot(232)\r\n",
        "plt.title('Distribution des {} top tags unitaires'.format(TOP))\r\n",
        "sns.histplot(temp.counts, kde=True)\r\n",
        "\r\n",
        "plt.subplot(235)\r\n",
        "sns.boxplot(x=temp.counts, width=0.2)\r\n",
        "\r\n",
        "plt.subplot(233)\r\n",
        "sns.histplot(train['nTags'], kde=True)\r\n",
        "plt.title('Distribution du nombre de tags par question')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4l-3mzJEmytS"
      },
      "source": [
        "pd.DataFrame(freq['Tags']).rename(columns={0:'Tag', 1:'count'}).describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9So4OZVEi2P"
      },
      "source": [
        "train[train.Tags.str.contains(\"c#\")][['Title', 'Body']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rc1AlMhrvtuB"
      },
      "source": [
        "# Réduction de dimensions\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LZ1EKm-v41a"
      },
      "source": [
        "## Tag unitaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv-9wnRaHlY4"
      },
      "source": [
        "train_1T = train[train.nTags == 1]\r\n",
        "freq = recap_cols(train_1T, cols)\r\n",
        "print(train.shape)\r\n",
        "train_1T.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Emm_dQkxmdlG"
      },
      "source": [
        "Réduction aux 50 top tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQcYaZppmgb6"
      },
      "source": [
        "cpt = 1\r\n",
        "train_1T = train_1T[train_1T.Tags.isin(dict(freq['Tags'][:TOP]).keys())]\r\n",
        "\r\n",
        "freq = recap_cols(train_1T, cols)\r\n",
        "\r\n",
        "fig = plt.figure(1, figsize=(25, 10))\r\n",
        "\r\n",
        "for col in cols:\r\n",
        "    plt.subplot(1, len(cols), cpt)\r\n",
        "    plt.barh([k for k, v in sorted(freq[col][:TOP], key=lambda x: x[1])], \r\n",
        "             [v for k, v in sorted(freq[col][:TOP], key=lambda x: x[1])])\r\n",
        "    plt.title('Top {} des mots dans \"{}\"'.format(TOP, col))\r\n",
        "    cpt += 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZkd8IhV_WdB"
      },
      "source": [
        "# Réduction du bag of words aux 2 mots les plus féquents pour chaque tag unitaire"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iimIen77NxJR"
      },
      "source": [
        "# Dictionnaire des index des enrgistrements contenant chaque tag\r\n",
        "dict_Tags = defaultdict(dict) \r\n",
        "\r\n",
        "for i, c in train.iterrows():\r\n",
        "    for t in c['Tags'].split():\r\n",
        "        try:\r\n",
        "            dict_Tags['idx'][t].append(i)\r\n",
        "        except KeyError:\r\n",
        "            dict_Tags['idx'][t] = [i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Py3Q3sByW16K"
      },
      "source": [
        "# Ajout des 2 mots les plus utilisés dans TItre et Body pour chaque tag \r\n",
        "tag_kw = set()\r\n",
        "\r\n",
        "for k in dict_Tags['idx'].keys():\r\n",
        "    temp = []\r\n",
        "    val = train[train.index.isin(dict_Tags['idx'][k])]['full']\r\n",
        "    new = Counter(' '.join(val).split()).most_common(2)\r\n",
        "    dict_Tags['kw'][k] = new\r\n",
        "    for i, j in new:\r\n",
        "        tag_kw.add(i)\r\n",
        "\r\n",
        "print('Soit {} radicaux distincts restants'.format(len(tag_kw)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsqTuedxkzrB"
      },
      "source": [
        "train2 = train.copy()\r\n",
        "train2.Title = train2.Title.apply(lambda x: ' '.join([w for w in x.split() if w in tag_kw]))\r\n",
        "train2.Body = train2.Body.apply(lambda x: ' '.join([w for w in x.split() if w in tag_kw]))\r\n",
        "\r\n",
        "freq2 = recap_cols(train2, cols)\r\n",
        "\r\n",
        "fig = plt.figure(1, figsize=(25, 10))\r\n",
        "cpt=1\r\n",
        "for col in cols:\r\n",
        "    plt.subplot(1, len(cols), cpt)\r\n",
        "    plt.barh([k for k, v in sorted(freq2[col][:TOP], key=lambda x: x[1])], \r\n",
        "             [v for k, v in sorted(freq2[col][:TOP], key=lambda x: x[1])])\r\n",
        "    plt.title('Top {} des mots dans \"{}\"'.format(TOP, col))\r\n",
        "    cpt += 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkUFH4oFINHU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13YB5_NlIPfJ"
      },
      "source": [
        "# Réduction du bag of words aux 2 mots les plus féquents pour chaque tag"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvFUUyUVIPfj"
      },
      "source": [
        "# Dictionnaire des index des enrgistrements contenant chaque tag\r\n",
        "dict_Tags = defaultdict(dict) \r\n",
        "\r\n",
        "for i, c in train.iterrows():\r\n",
        "    try:\r\n",
        "        dict_Tags['idx'][c['Tags']].append(i)\r\n",
        "    except KeyError:\r\n",
        "        dict_Tags['idx'][c['Tags']] = [i]\r\n",
        "\r\n",
        "print('{} tags'.format(len(dict_Tags['idx'])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_RrJxlcGIPfl"
      },
      "source": [
        "# Ajout des 2 mots les plus utilisés dans TItre et Body pour chaque tag \r\n",
        "tag_kw = set()\r\n",
        "\r\n",
        "for k in dict_Tags['idx'].keys():\r\n",
        "    temp = []\r\n",
        "    val = train[train.index.isin(dict_Tags['idx'][k])]['full']\r\n",
        "    new = Counter(' '.join(val).split()).most_common(2)\r\n",
        "    dict_Tags['kw'][k] = new\r\n",
        "    for i, j in new:\r\n",
        "        tag_kw.add(i)\r\n",
        "\r\n",
        "print('Soit {} radicaux distincts restants'.format(len(tag_kw)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jumeFNlVIPfp"
      },
      "source": [
        "train2 = train.copy()\r\n",
        "train2.Title = train2.Title.apply(lambda x: ' '.join([w for w in x.split() if w in tag_kw]))\r\n",
        "train2.Body = train2.Body.apply(lambda x: ' '.join([w for w in x.split() if w in tag_kw]))\r\n",
        "\r\n",
        "cols = ['Title', 'Body', 'Tags']\r\n",
        "freq2 = recap_cols(train2, cols)\r\n",
        "\r\n",
        "fig = plt.figure(1, figsize=(25, 10))\r\n",
        "cpt=1\r\n",
        "for col in cols:\r\n",
        "    plt.subplot(1, len(cols), cpt)\r\n",
        "    plt.barh([k for k, v in sorted(freq2[col][:TOP], key=lambda x: x[1])], \r\n",
        "             [v for k, v in sorted(freq2[col][:TOP], key=lambda x: x[1])])\r\n",
        "    plt.title('Top {} des mots dans \"{}\"'.format(TOP, col))\r\n",
        "    cpt += 1 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcBGv99jgcQ1"
      },
      "source": [
        "# Export"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz2al4MZclv5"
      },
      "source": [
        "with open('OC_DS_P6_backup.pkl', 'wb') as file:\r\n",
        "    pickler = pickle.Pickler(file, pickle.HIGHEST_PROTOCOL) \r\n",
        "    pickler.dump(train2)\r\n",
        "    pickler.dump(EXTRA_SW)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lr8rD_375piI"
      },
      "source": [
        "len(dict_Tags['kw'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2pMwC25kGSt"
      },
      "source": [
        "train[train2.Tags.str.contains('emacs')]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}